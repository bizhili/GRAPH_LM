{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import modules.standard as standard\n",
    "import modules.plotGraph as plotGraph\n",
    "import modules.centrality as centrality\n",
    "import math\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrixs(n, seed= 11, maxLen= 100):#n from 10 to 100\n",
    "    m= int(math.log(n))\n",
    "    random.seed(seed)\n",
    "    graphSD= standard.generate_random_standard_graph(n, m)\n",
    "    graphWS= nx.watts_strogatz_graph(n, m*2, 0.1)\n",
    "    graphER= nx.dense_gnm_random_graph(n, m*n)\n",
    "    graphBA= nx.barabasi_albert_graph(n, m)\n",
    "    graphs= [graphSD, graphWS, graphER, graphBA]\n",
    "    myEmbdeddingNps= []\n",
    "    centralitysNps= []\n",
    "    for graph in graphs:\n",
    "        idS, exclude=standard.compress_left_order(nx.to_numpy_array(graph))\n",
    "        standardNP= standard.standardize(graph, traversal=list(idS)+list(exclude))# a kind of embedding,  150, \n",
    "        standardGraph= nx.Graph(standardNP)\n",
    "        myEmbdeddingNp=standard.power_m_embedding(standardNP, Precision= 5, length= 20, m= 0.5)\n",
    "        eigenvectorCentralityNp= centrality.eigenvector_centrality_embedding(standardGraph)\n",
    "        closenessCentralityNp= centrality.closeness_centrality_embedding(standardGraph)\n",
    "        degreeCentralityNp= centrality.degree_centrality_embedding(standardGraph)\n",
    "        loadCentralityNp= centrality.load_centrality_embedding(standardGraph)\n",
    "        betweennessCentralityNp= centrality.betweenness_centrality_embedding(standardGraph)\n",
    "        centralitys=[eigenvectorCentralityNp, closenessCentralityNp, degreeCentralityNp, loadCentralityNp, betweennessCentralityNp]\n",
    "        centralitysNp= np.stack(centralitys)\n",
    "        centralitysNpMax= np.zeros((5, maxLen))\n",
    "        centralitysNpMax[:, 0: n]= centralitysNp\n",
    "        myEmbdeddingNps.append(myEmbdeddingNp)\n",
    "        centralitysNps.append(centralitysNpMax)\n",
    "    return myEmbdeddingNps, centralitysNps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 12/90 [00:06<00:46,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save file: datas/data1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 25/90 [00:20<01:24,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save file: datas/data2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 37/90 [00:41<01:45,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save file: datas/data3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 50/90 [01:18<02:13,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save file: datas/data4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 62/90 [02:09<02:06,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save file: datas/data5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 75/90 [03:23<01:32,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save file: datas/data6.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 87/90 [04:52<00:23,  7.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save file: datas/data7.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [05:18<00:00,  3.53s/it]\n"
     ]
    }
   ],
   "source": [
    "myEmbdeddingNpss= []\n",
    "centralitysNpss= []\n",
    "lenData= 2500\n",
    "count= 1\n",
    "maxLen= 100\n",
    "for i in tqdm(range(10, 100)):\n",
    "    for j in range(50):\n",
    "        seed= i*50+j\n",
    "        EmbdeddingNps, mycentralitysNps= create_matrixs(i, seed, maxLen)\n",
    "        myEmbdeddingNpss+= EmbdeddingNps\n",
    "        centralitysNpss+= mycentralitysNps\n",
    "        if len(myEmbdeddingNpss)>=lenData:\n",
    "            with h5py.File(f'datas/data{count}.h5', 'w') as f:#2500 matrices one file\n",
    "                for k in range(lenData):\n",
    "                    # Create a dataset from the NumPy array\n",
    "                    f.create_dataset(f'M{k}', data= myEmbdeddingNpss[k])\n",
    "                    f.create_dataset(f'C1{k}', data= centralitysNpss[k])\n",
    "            print(f\"save file: datas/data{count}.h5\")\n",
    "            count+=1\n",
    "            myEmbdeddingNpss.clear()\n",
    "            centralitysNpss.clear() \n",
    "\n",
    "#5*90*10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
